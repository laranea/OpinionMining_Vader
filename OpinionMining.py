# -*- coding: utf-8 -*-
"""OpinionMining.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10229ijjnCbOW2tW3QXDoB98tTR6AL0z-
"""

import tweepy
import pandas as pd
from nltk.sentiment.vader import SentimentIntensityAnalyzer
import nltk
nltk.download('vader_lexicon')

api_key = "Your api key here."
api_secret_key = "Your api secret key here"

access_token = "Your access token here"
access_secret_token = "Your access secret access token here"

auth = tweepy.OAuthHandler(api_key, api_secret_key)
auth.set_access_token(access_token, access_secret_token)

api = tweepy.API(auth)

topic = input("Enter the topic you want to analyze?")

tweets = api.search(topic, count=10000000)


data = pd.DataFrame(data=[tweet.text for tweet in tweets], columns=['Tweets'])

# display(data)


print(tweets[0].created_at)

sentiment_id = SentimentIntensityAnalyzer()


lists = []

for index, row in data.iterrows():
  sentiment_score = sentiment_id.polarity_scores(row["Tweets"])
  lists.append(sentiment_score)
  
se = pd.Series(lists)
data['polarity'] = se.values

display(data.head(10))

neg_polarity = 0
pos_polarity = 0
neutral_polarity = 0

for results in data['polarity']:
  neg_polarity += results['neg']
  pos_polarity += results['pos']
  neutral_polarity += results['neu']
  
neg_polarity = neg_polarity/len(data)
pos_polarity = pos_polarity/len(data)
neutral_polarity = neutral_polarity/len(data)


print(neg_polarity*100)
print(pos_polarity*100)
print(neutral_polarity*100)

Total = pos_polarity + neg_polarity
Pos_percentage = pos_polarity/ Total *100
Neg_percentage = neg_polarity/Total * 100

print("Positive: "+str(Pos_percentage))
print("Negative: "+str(Neg_percentage))
